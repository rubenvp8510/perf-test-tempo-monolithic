# Performance Test Load Configurations - IMPROVED VERSION
# 
# This configuration fixes the resource consumption anomaly where low loads
# consumed more resources than high loads. Key improvements:
#
# 1. Proportional query scaling: QPS scales linearly with ingestion rate
#    - Maintains ~20 QPS per MB/s ratio across all loads
# 2. Proper concurrent query scaling with load
# 3. Longer test duration with warm-up period (45min total)
# 4. Adaptive rate windows for metric collection
#

# Test duration: 45 minutes (15min warm-up + 30min stable measurement)
# Metrics are collected for the last 30 minutes only to avoid cold-start effects
testDuration: "45m"

# Namespace where tests will run
namespace: "tempo-perf-test"

# Multitenancy configuration
tenants:
  - id: "tenant-1"
    description: "Default tenant for performance testing"

# OpenTelemetry Collector configuration
otelCollector:
  serviceName: "otel-collector-collector"
  port: 4317

# Tempo endpoint configuration
tempo:
  host: "tempo-simplest"
  grpcPort: 4317
  jaegerUIPort: 16686

# Estimation config
estimatedBytesPerSpan: 800

# Service configurations (unchanged - working well)
services:
  - name: "frontend"
    depth: 3
    nspans: 8
    weight: 30
  - name: "api-gateway"
    depth: 5
    nspans: 15
    weight: 25
  - name: "order-service"
    depth: 8
    nspans: 35
    weight: 20
  - name: "payment-service"
    depth: 4
    nspans: 12
    weight: 10
  - name: "inventory-service"
    depth: 6
    nspans: 25
    weight: 15

# IMPROVED Load configurations
# Key change: queryQPS now scales proportionally with ingestion rate
# Target ratio: ~20 QPS per MB/s (Â±10%)
loads:
  - name: "low"
    description: "Low load - baseline test"
    mb_per_sec: 0.7
    parallelism: 2
    tps_multiplier: 4
    # FIXED: Reduced from 25 to 15 QPS (21.4 QPS/MB ratio)
    queryQPS: 15
    concurrentQueries: 2
    # Shorter measurement window for low load
    measurementWindow: "1m"

  - name: "medium"
    description: "Medium load - typical production"
    mb_per_sec: 2.0
    parallelism: 3
    tps_multiplier: 2.4
    # FIXED: Reduced from 50 to 40 QPS (20.0 QPS/MB ratio)
    queryQPS: 40
    concurrentQueries: 3
    measurementWindow: "3m"

  - name: "high"
    description: "High load - stress test"
    mb_per_sec: 4.0
    parallelism: 4
    tps_multiplier: 1.8
    # FIXED: Increased from 75 to 80 QPS (20.0 QPS/MB ratio)
    queryQPS: 80
    concurrentQueries: 5
    measurementWindow: "5m"

  - name: "very-high"
    description: "Very high load - peak capacity test"
    mb_per_sec: 7.0
    parallelism: 5
    tps_multiplier: 1.45
    # FIXED: Increased from 75 to 140 QPS (20.0 QPS/MB ratio)
    # This is the critical fix - was same as "high" despite 1.75x more ingestion
    queryQPS: 140
    concurrentQueries: 8
    qpsMultiplier: 1.0
    measurementWindow: "5m"

# Query generator configuration
queryGenerator:
  image: "quay.io/rvargasp/query-load-generator:latest"
  delay: "15m"  # CHANGED: 15-minute warm-up before starting queries
  concurrentQueries: 5
  burstMultiplier: 2.0


